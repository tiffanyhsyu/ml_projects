{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import powerlaw\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Activation, Dense, Input, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model, multi_gpu_model, np_utils\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for predicting the mean, standard deviation of 2D Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict() -- generate new Gaussians, apply model, plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    # Make 1000 new Gaussians to apply the model to\n",
    "    predX, predy = make_gaussians(1000, add_noise=True)\n",
    "        \n",
    "    # Apply the model to get predicted means and sigmas of the Gaussians\n",
    "    pamp, pxmu, pxsig, pymu, pysig = model.predict(predX, batch_size=None, verbose=0)\n",
    "    \n",
    "    # Check distribution of difference between true and predicted means, sigmas\n",
    "    plt.subplot(511)\n",
    "    _, _, _ = plt.hist(predy[:, 0] - pamp.flatten(), bins=30)\n",
    "    plt.subplot(512)\n",
    "    _, _, _ = plt.hist(predy[:, 1] - pxmu.flatten(), bins=30)\n",
    "    plt.subplot(513)\n",
    "    _, _, _ = plt.hist(predy[:, 2] - pxsig.flatten(), bins=30)\n",
    "    plt.subplot(514)\n",
    "    _, _, _ = plt.hist(predy[:, 3] - pymu.flatten(), bins=30)\n",
    "    plt.subplot(515)\n",
    "    _, _, _ = plt.hist(predy[:, 4] - pysig.flatten(), bins=30)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Check the relation between true and predicted means, sigmas\n",
    "    oto_amp = np.linspace(1., 10., 32) #one-to-one relation for amplitudes\n",
    "    oto_means = np.linspace(-1., 1., 32) # one-to-one relation for means\n",
    "    oto_sigmas = np.linspace(0.25, 4.0, 32) # one-to-one relation for sigmas\n",
    "    \n",
    "    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 4))\n",
    "    \n",
    "    # Plot the true y's and predicted y's from the NN model\n",
    "    ax1.scatter(predy[:, 0], pamp.flatten(), marker='.')\n",
    "    # Plot the 1-to-1 line\n",
    "    ax1.plot(oto_amp, oto_amp, color='black', ls='--')\n",
    "    ax1.set_xlabel('True value')\n",
    "    ax1.set_ylabel('Predicted value')\n",
    "    ax1.set_title(r'Gaussian Amplitude')\n",
    "\n",
    "    ax2.scatter(predy[:, 1], pxmu.flatten(), marker='.')\n",
    "    ax2.plot(oto_means, oto_means, color='black', ls='--')\n",
    "    ax2.set_xlabel('True value')\n",
    "    ax2.set_ylabel('Predicted value')\n",
    "    ax2.set_title(r'Gaussian x-$\\mu$')\n",
    "    \n",
    "    ax3.scatter(predy[:, 2], pxsig.flatten(), marker='.')\n",
    "    ax3.plot(oto_sigmas, oto_sigmas, color='black', ls='--')\n",
    "    ax3.set_xlabel('True value')\n",
    "    ax3.set_ylabel('Predicted value')\n",
    "    ax3.set_title(r'Gaussian x-$\\sigma$')\n",
    "    \n",
    "    ax4.scatter(predy[:, 3], pymu.flatten(), marker='.')\n",
    "    ax4.plot(oto_means, oto_means, color='black', ls='--')\n",
    "    ax4.set_xlabel('True value')\n",
    "    ax4.set_ylabel('Predicted value')\n",
    "    ax4.set_title(r'Gaussian y-$\\mu$')\n",
    "    \n",
    "    ax5.scatter(predy[:, 4], pysig.flatten(), marker='.')\n",
    "    ax5.plot(oto_sigmas, oto_sigmas, color='black', ls='--')\n",
    "    ax5.set_xlabel('True value')\n",
    "    ax5.set_ylabel('Predicted value')\n",
    "    ax5.set_title(r'Gaussian y-$\\sigma$')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2D Gaussians given mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a 2d Gaussian given its mean and standard deviation\n",
    "def gaussian2d(x_vals, y_vals, amp, x_mu, x_sigma, y_mu, y_sigma):\n",
    "    return amp * np.exp(-0.5 * ( ((x_vals - x_mu)/x_sigma)**2 + ((y_vals - y_mu)/y_sigma)**2 ))\n",
    "\n",
    "# Make array that describes Gaussian\n",
    "def make_gaussians(num, amp_min=1., amp_max = 10.0, mu_min=-1.0, mu_max=1.0, sig_min=0.25, sig_max=4.0, add_noise=False): \n",
    "\n",
    "    # Random Gaussian distribution\n",
    "    #amp = np.random.uniform(amp_min, amp_max, num)\n",
    "    \n",
    "    # Power law distribution\n",
    "    pwr_law = powerlaw.rvs(4, size=num)\n",
    "    amp = amp_max * pwr_law\n",
    "    \n",
    "    # 'Classification': if pwr_law <= 0.5 --> 'XMP' = 1.\n",
    "    classification = np.zeros(num)\n",
    "    classification[np.where(pwr_law <= 0.5)[0]] = 1.\n",
    "    #classification = np_utils.to_categorical(classification)\n",
    "    \n",
    "    x_mus = np.random.uniform(mu_min, mu_max, num)\n",
    "    #x_sigmas = np.random.uniform(sig_min, sig_max, num)\n",
    "    x_sigmas = pwr_law**2 * sig_max\n",
    "    \n",
    "    y_mus = np.random.uniform(mu_min, mu_max, num)\n",
    "    #y_sigmas = np.random.uniform(sig_min, sig_max, num)\n",
    "    y_sigmas = pwr_law**3\n",
    "\n",
    "    x_vals = np.linspace(-10.0, 10.0, 32)\n",
    "    y_vals = np.linspace(-10.0, 10.0, 32)\n",
    "    \n",
    "    x_grid, y_grid = np.meshgrid(x_vals, y_vals)\n",
    "    \n",
    "    models = np.zeros((num, 32, 32))\n",
    "    noise = np.zeros((num, 32, 32))\n",
    "    noise_stds = np.random.uniform(0.0, sig_max, num)\n",
    "    \n",
    "    #if add_noise:\n",
    "        # Add some noise -- currently noise is Gaussian but all with same standard deviation = 1.0\n",
    "    #    noise = np.random.normal(0.0, 1.0, models.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        models[i] = gaussian2d(x_grid, y_grid, amp[i], x_mus[i], x_sigmas[i], y_mus[i], y_sigmas[i])\n",
    "        \n",
    "        if add_noise:\n",
    "            noise[i] = np.random.normal(0.0, noise_stds[i], models[0].shape)\n",
    "    \n",
    "    # Also want to save and return the true means, sigmas used for the Gaussians\n",
    "    targets = np.vstack((amp, x_mus, x_sigmas, y_mus, y_sigmas)).T\n",
    "    \n",
    "    models = models.reshape(num, 32, 32, 1)\n",
    "    noise = noise.reshape(num, 32, 32, 1)\n",
    "\n",
    "    return models + noise, targets, classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_dataset() -- wrapper to make n_train, n_test Gaussians and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "def generate_dataset(n_train=10000, n_test=1000):\n",
    "    X_train, y_train, class_train = make_gaussians(n_train, add_noise=True)\n",
    "    X_test, y_test, class_test = make_gaussians(n_test, add_noise=True)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, class_train, class_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams() -- generate random hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam(mnum):\n",
    "    '''\n",
    "    Generate a random set of hyperparameters\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    mnum (int) : model index number\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hyperpar : dict\n",
    "    \n",
    "    '''\n",
    "    # Define all of the allowed parameter space\n",
    "    allowed_hpars = dict(learning_rate      = [0.0005, 0.0007, 0.0010, 0.0030, 0.0050, 0.0070, 0.0100],\n",
    "                         lr_decay           = [0.0, 1.0],\n",
    "                         num_epochs         = [30, 50, 80],\n",
    "                         batch_size         = [16, 32, 64, 128], #100, 500, 1000, 2000, 5000],\n",
    "\n",
    "                         # Number of filters in each convolutional layer\n",
    "                         conv_filter_1 = [4, 8, 16, 32], #64], \n",
    "                         conv_filter_2 = [2, 4, 8, 16], #32, 64], \n",
    "                         \n",
    "                         # Kernel size\n",
    "                         conv_kernel_1 = [2, 3, 4, 5],\n",
    "                         conv_kernel_2 = [1, 2, 3, 4],\n",
    "                         \n",
    "                         # Stride of each kernal\n",
    "                         #conv_stride_1 = [1, 2, 4, 6],\n",
    "                         #conv_stride_2 = [1, 2, 4, 6],\n",
    "                         #conv_stride_3 = [1, 2, 4, 6],\n",
    "                         \n",
    "                         # Pooling kernel size\n",
    "                         pool_kernel_1 = [2, 3, 4, 5],\n",
    "\n",
    "                         # Pooling stride\n",
    "                         #pool_stride_1 = [1, 2, 3],\n",
    "                         #pool_stride_2 = [1, 2, 3],\n",
    "                         #pool_stride_3 = [1, 2, 3],\n",
    "                         \n",
    "                         # Fully connected layers\n",
    "                         fc1_neurons   = [64, 128, 256, 512],\n",
    "                         )\n",
    "    \n",
    "    # Generate dictionary of values\n",
    "    hyperpar = dict({})\n",
    "    for key in allowed_hpars.keys():\n",
    "        hyperpar[key] = np.random.choice(allowed_hpars[key])\n",
    "    \n",
    "    print ('\\t Hyperparameters:')\n",
    "    print (hyperpar)\n",
    "    \n",
    "    # Save these parameters and return the hyperpar\n",
    "    save_obj(hyperpar, 'model_{0:03d}_hyperparams'.format(mnum))\n",
    "    print ('\\t Saved hyperparameters!')\n",
    "    \n",
    "    return hyperpar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build_model() -- given random hyperparameters, build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperpar):\n",
    "    # Extract parameters from hyperparameter set\n",
    "    conv1_filter = hyperpar['conv_filter_1']\n",
    "    conv2_filter = hyperpar['conv_filter_2']\n",
    "    \n",
    "    conv1_kernel = hyperpar['conv_kernel_1']\n",
    "    conv2_kernel = hyperpar['conv_kernel_2']\n",
    "\n",
    "    pool1_kernel = hyperpar['pool_kernel_1']\n",
    "    \n",
    "    fc1_neurons = hyperpar['fc1_neurons']\n",
    "\n",
    "    # Build model\n",
    "    print ('\\t Building model from hyperparameters...')\n",
    "    input1 = Input(shape=(32, 32, 1))#X_train.shape[1], X_train.shape[2], X_train.shape[3])) # this returns the 32x32 2d array of Gaussian\n",
    "    \n",
    "    conv1 = Conv2D(filters=conv1_filter, kernel_size=(conv1_kernel, conv1_kernel), activation='relu')(input1)\n",
    "    conv2 = Conv2D(filters=conv2_filter, kernel_size=(conv2_kernel, conv2_kernel), activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(pool1_kernel, pool1_kernel))(conv2)    \n",
    "    \n",
    "    flat1 = Flatten()(pool1)\n",
    "    fc1 = Dense(fc1_neurons, activation='relu')(flat1)\n",
    "    \n",
    "    out1 = Dense(1, activation='linear', name='amplitude')(fc1)\n",
    "    out2 = Dense(1, activation='linear', name='x_mean')(fc1)\n",
    "    out3 = Dense(1, activation='linear', name='x_sigma')(fc1)\n",
    "    out4 = Dense(1, activation='linear', name='y_mean')(fc1)\n",
    "    out5 = Dense(1, activation='linear', name='y_sigma')(fc1)\n",
    "    out6 = Dense(1, activation='sigmoid', name='classification')(fc1)\n",
    "    \n",
    "    model = Model(inputs=input1, outputs=[out1, out2, out3, out4, out5, out6])\n",
    "    #model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create, compile, fit, and evaluate NN model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check out: https://datascience.stackexchange.com/questions/28003/get-multiple-output-from-keras\n",
    "# for multi-output regression using Keras NNs\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    # Create model\n",
    "    # Here, this means that our training set of 10000 samples will be divided into\n",
    "    # 10000/batch_size = 10000/16 = 625 batches, each with 16 samples. The model\n",
    "    # weights will be updated after each batch of 16. One epoch will involve 625 batches.\n",
    "    verbose, epochs, batch_size = 1, 100, 16\n",
    "\n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])) # this returns the 32x32 2d array of Gaussian\n",
    "\n",
    "    x = Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs)\n",
    "    x = Conv2D(filters=8, kernel_size=(2,2), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)    \n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    \n",
    "    out1 = Dense(1, activation='linear', name='amplitude')(x)\n",
    "    out2 = Dense(1, activation='linear', name='x_mean')(x)\n",
    "    out3 = Dense(1, activation='linear', name='x_sigma')(x)\n",
    "    out4 = Dense(1, activation='linear', name='y_mean')(x)\n",
    "    out5 = Dense(1, activation='linear', name='y_sigma')(x)\n",
    "\n",
    "    # Create model with input layer and dense layers\n",
    "    model = Model(inputs=inputs, outputs=[out1, out2, out3, out4, out5])\n",
    "    model.summary()\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, [y_train[:,0], y_train[:,1], y_train[:,2], y_train[:,3], y_train[:,4]], \n",
    "              epochs=epochs, verbose=verbose)\n",
    "    \n",
    "    # Run model on test set\n",
    "    loss = model.evaluate(X_test, [y_test[:,0], y_test[:,1], y_test[:,2], y_test[:,3], y_test[:,4]], \n",
    "                          batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    predict(model)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evalute_model() -- read in randomized hyperparameters to compile and fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all struggles with h5py saving models: https://stackoverflow.com/questions/60917467/alternating-errors-using-hdf5-library-and-h5py-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, class_train, class_test, hyperpar, mnum, verbose=1):\n",
    "    filepath = os.getcwd() + '/' #os.path.dirname(os.path.abspath(__file__))\n",
    "    model_name = 'model_{0:03d}'.format(mnum)\n",
    "    print ('\\t Creating model', model_name)\n",
    "\n",
    "    # Construct neural network, depending on GPUs\n",
    "    ngpus = len(get_available_gpus())\n",
    "    if ngpus > 1:\n",
    "        model = build_model(hyperpar)\n",
    "        # Make this work on multiple GPUs\n",
    "        gpumodel = multi_gpu_model(model, gpus=ngpus)\n",
    "    else:\n",
    "        gpumodel = build_model(hyperpar)\n",
    "\n",
    "    # Summarize layers\n",
    "    summary = False\n",
    "    if summary:\n",
    "        with open(filepath + model_name + '.summary', 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                model.summary()\n",
    "    # Plot graph\n",
    "    plotit = False\n",
    "    if plotit:\n",
    "        pngname = filepath + model_name + '.png'\n",
    "        plot_model(model, to_file=pngname)\n",
    "\n",
    "    # Compile model\n",
    "    decay = hyperpar['lr_decay']*hyperpar['learning_rate'] / hyperpar['num_epochs']\n",
    "    optadam = Adam(lr=hyperpar['learning_rate'], decay=decay)\n",
    "\n",
    "    gpumodel.compile(loss=['mse', 'mse', 'mse', 'mse', 'mse', 'binary_crossentropy'], optimizer=optadam)#, metrics=['mean_squared_error'])\n",
    "\n",
    "    # Initialise callbacks\n",
    "    ckp_name = filepath + model_name + '.hdf5'\n",
    "    sav_name = filepath + model_name + '_save.hdf5'\n",
    "    csv_name = filepath + model_name + '.log'\n",
    "    checkpointer = ModelCheckpoint(filepath=ckp_name, verbose=1, save_best_only=True)\n",
    "    csv_logger = CSVLogger(csv_name, append=True)\n",
    "\n",
    "    # Fit network\n",
    "    gpumodel.fit(X_train, [y_train[:,0], y_train[:,1], y_train[:,2], y_train[:,3], y_train[:,4], class_train],\n",
    "        epochs=hyperpar['num_epochs'], verbose=verbose)\n",
    "\n",
    "    gpumodel.save(sav_name)\n",
    "    print ('\\t Saved model ' + sav_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    accuracy = gpumodel.evaluate(X_test, [y_test[:,0], y_test[:,1], y_test[:,2], y_test[:,3], y_test[:,4], class_test], \n",
    "        batch_size=hyperpar['batch_size'], verbose=0)\n",
    "\n",
    "    return accuracy, gpumodel.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_model(model_name, X_train, y_train, X_test, y_test, class_train, class_test, epochs=50, batch_size=16, verbose=1):\n",
    "    # Load model    \n",
    "    filepath = os.getcwd() + '/' #os.path.dirname(os.path.abspath(__file__))+'/'\n",
    "    loadname = filepath + model_name + '.hdf5'\n",
    "    \n",
    "    print ('\\t Loading model...')\n",
    "    model = load_model(loadname, compile=False)\n",
    "\n",
    "    # Make this work on multiple GPUs\n",
    "    gpumodel = model #multi_gpu_model(model, gpus=4)\n",
    "\n",
    "    gpumodel.compile(loss=['mse', 'mse', 'mse', 'mse', 'mse', 'binary_crossentropy'], optimizer='adam')#, metrics=['mean_squared_error'])\n",
    "    \n",
    "    # Initialise callbacks\n",
    "    ckp_name = filepath + model_name + '_chkp_restart.hdf5'\n",
    "    sav_name = filepath + model_name + '_save_restart.hdf5'\n",
    "    csv_name = filepath + model_name + '_restart.log'\n",
    "    checkpointer = ModelCheckpoint(filepath=ckp_name, verbose=1, save_best_only=True)\n",
    "    csv_logger = CSVLogger(csv_name, append=True)\n",
    "    \n",
    "    # Fit network\n",
    "    print ('\\t Re-fitting model')\n",
    "    gpumodel.fit(X_train, [y_train[:,0], y_train[:,1], y_train[:,2], y_train[:,3], y_train[:,4], class_train],\n",
    "        epochs=epochs, verbose=verbose)\n",
    "\n",
    "    print ('\\t Saving model restart')\n",
    "    gpumodel.save(sav_name)\n",
    "\n",
    "    # Evaluate model\n",
    "    print ('\\t Evaluating model')\n",
    "    accuracy = gpumodel.evaluate(X_test, [y_test[:,0], y_test[:,1], y_test[:,2], y_test[:,3], y_test[:,4], class_test], \n",
    "        batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return accuracy, gpumodel.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If relevant, check accuracy of the model\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    keys = scores.keys()\n",
    "    \n",
    "    for ii in keys:\n",
    "        m, s = np.mean(scores[ii]), np.std(scores[ii])\n",
    "        \n",
    "        print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "# Save and load model\n",
    "def save_obj(obj, dirname):\n",
    "    with open(dirname + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_obj(dirname):\n",
    "    with open(dirname + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def detect_features(repeats=1):\n",
    "    # Generate data\n",
    "    X_train, y_train, X_test, y_test = generate_dataset()\n",
    "    \n",
    "    # Repeat experiment\n",
    "    scores = list()\n",
    "    \n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        # **** score[0] below is currently the loss\n",
    "        score = np.asarray(score[0]) * 100.0\n",
    "        print('>#%d: %.3f' % (r + 1, score))\n",
    "        scores.append(score)\n",
    "        \n",
    "    # Summarize results\n",
    "    #summarize_results(scores)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "detect_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect features in a dataset\n",
    "def localise_features(mnum, repeats=3, restart=False):\n",
    "    # Generate hyperparameters\n",
    "    if not restart:\n",
    "        hyperpar = hyperparam(mnum)\n",
    "        print ('\\t Generated hyperparameters')\n",
    "\n",
    "    # Generate data\n",
    "    X_train, y_train, X_test, y_test, class_train, class_test = generate_dataset()\n",
    "    print ('\\t Generated dataset')\n",
    "    \n",
    "    # repeat experiment\n",
    "    allscores = dict({})\n",
    "    \n",
    "    for r in range(repeats):\n",
    "        if restart:\n",
    "            model_name = 'model_002_save'\n",
    "            print ('\\t Restarting model ', model_name)\n",
    "            scores, names = restart_model(model_name, X_train, y_train, X_test, y_test, class_train, class_test)\n",
    "        else:\n",
    "            scores, names = evaluate_model(X_train, y_train, X_test, y_test, class_train, class_test, hyperpar, mnum)\n",
    "        if r == 0:\n",
    "            for name in names:\n",
    "                #pdb.set_trace()\n",
    "                allscores[name] = []\n",
    "        for ii, name in enumerate(names):\n",
    "            #pdb.set_trace()\n",
    "            allscores[name].append(scores[ii] * 100.0)\n",
    "            if '_acc' in name:\n",
    "                print('%s >#%d: %.3f' % (name, r + 1, allscores[name][-1]))\n",
    "            else:\n",
    "                print('%s >#%d: %.3f' % (name, r + 1, scores[ii]))\n",
    "                \n",
    "    # Summarize results\n",
    "    #summarize_results(allscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " 0\n",
      "\t Hyperparameters:\n",
      "{'learning_rate': 0.0007, 'lr_decay': 1.0, 'num_epochs': 50, 'batch_size': 128, 'conv_filter_1': 16, 'conv_filter_2': 8, 'conv_kernel_1': 3, 'conv_kernel_2': 2, 'pool_kernel_1': 2, 'fc1_neurons': 256}\n",
      "\t Saved hyperparameters!\n",
      "\t Generated hyperparameters\n",
      "\t Generated dataset\n",
      "\t Creating model model_000\n",
      "\t Building model from hyperparameters...\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 6s 623us/step - loss: 3.6687 - amplitude_loss: 2.5686 - x_mean_loss: 0.2848 - x_sigma_loss: 0.3473 - y_mean_loss: 0.1745 - y_sigma_loss: 0.1161 - classification_loss: 0.1730\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 6s 615us/step - loss: 0.8342 - amplitude_loss: 0.3812 - x_mean_loss: 0.1534 - x_sigma_loss: 0.0754 - y_mean_loss: 0.0745 - y_sigma_loss: 0.0250 - classification_loss: 0.1249\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.6686 - amplitude_loss: 0.3067 - x_mean_loss: 0.1317 - x_sigma_loss: 0.0560 - y_mean_loss: 0.0606 - y_sigma_loss: 0.0141 - classification_loss: 0.0996\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 6s 622us/step - loss: 0.5636 - amplitude_loss: 0.2540 - x_mean_loss: 0.1200 - x_sigma_loss: 0.0455 - y_mean_loss: 0.0511 - y_sigma_loss: 0.0100 - classification_loss: 0.0831\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 6s 615us/step - loss: 0.4959 - amplitude_loss: 0.2198 - x_mean_loss: 0.1103 - x_sigma_loss: 0.0410 - y_mean_loss: 0.0451 - y_sigma_loss: 0.0071 - classification_loss: 0.0725\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.4319 - amplitude_loss: 0.1829 - x_mean_loss: 0.1044 - x_sigma_loss: 0.0342 - y_mean_loss: 0.0398 - y_sigma_loss: 0.0060 - classification_loss: 0.0651\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.4002 - amplitude_loss: 0.1670 - x_mean_loss: 0.0984 - x_sigma_loss: 0.0319 - y_mean_loss: 0.0380 - y_sigma_loss: 0.0055 - classification_loss: 0.0593\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.3565 - amplitude_loss: 0.1442 - x_mean_loss: 0.0914 - x_sigma_loss: 0.0280 - y_mean_loss: 0.0346 - y_sigma_loss: 0.0046 - classification_loss: 0.0537\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.3238 - amplitude_loss: 0.1262 - x_mean_loss: 0.0870 - x_sigma_loss: 0.0253 - y_mean_loss: 0.0318 - y_sigma_loss: 0.0041 - classification_loss: 0.0495\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 6s 615us/step - loss: 0.2984 - amplitude_loss: 0.1147 - x_mean_loss: 0.0819 - x_sigma_loss: 0.0233 - y_mean_loss: 0.0300 - y_sigma_loss: 0.0038 - classification_loss: 0.0449\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.2803 - amplitude_loss: 0.1118 - x_mean_loss: 0.0726 - x_sigma_loss: 0.0225 - y_mean_loss: 0.0273 - y_sigma_loss: 0.0039 - classification_loss: 0.0423\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 6s 611us/step - loss: 0.2467 - amplitude_loss: 0.0941 - x_mean_loss: 0.0671 - x_sigma_loss: 0.0196 - y_mean_loss: 0.0254 - y_sigma_loss: 0.0032 - classification_loss: 0.0374\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.2287 - amplitude_loss: 0.0902 - x_mean_loss: 0.0597 - x_sigma_loss: 0.0182 - y_mean_loss: 0.0238 - y_sigma_loss: 0.0029 - classification_loss: 0.0343\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.2053 - amplitude_loss: 0.0800 - x_mean_loss: 0.0526 - x_sigma_loss: 0.0165 - y_mean_loss: 0.0222 - y_sigma_loss: 0.0027 - classification_loss: 0.0316\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.1878 - amplitude_loss: 0.0743 - x_mean_loss: 0.0473 - x_sigma_loss: 0.0150 - y_mean_loss: 0.0207 - y_sigma_loss: 0.0027 - classification_loss: 0.0278\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.1658 - amplitude_loss: 0.0628 - x_mean_loss: 0.0446 - x_sigma_loss: 0.0129 - y_mean_loss: 0.0182 - y_sigma_loss: 0.0021 - classification_loss: 0.0252\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 6s 603us/step - loss: 0.1561 - amplitude_loss: 0.0622 - x_mean_loss: 0.0392 - x_sigma_loss: 0.0125 - y_mean_loss: 0.0171 - y_sigma_loss: 0.0019 - classification_loss: 0.0231\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.1404 - amplitude_loss: 0.0544 - x_mean_loss: 0.0359 - x_sigma_loss: 0.0114 - y_mean_loss: 0.0165 - y_sigma_loss: 0.0018 - classification_loss: 0.0206\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.1337 - amplitude_loss: 0.0549 - x_mean_loss: 0.0318 - x_sigma_loss: 0.0112 - y_mean_loss: 0.0154 - y_sigma_loss: 0.0017 - classification_loss: 0.0190\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.1246 - amplitude_loss: 0.0492 - x_mean_loss: 0.0316 - x_sigma_loss: 0.0104 - y_mean_loss: 0.0144 - y_sigma_loss: 0.0017 - classification_loss: 0.0174\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.1082 - amplitude_loss: 0.0407 - x_mean_loss: 0.0283 - x_sigma_loss: 0.0089 - y_mean_loss: 0.0130 - y_sigma_loss: 0.0016 - classification_loss: 0.0157\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.1059 - amplitude_loss: 0.0415 - x_mean_loss: 0.0268 - x_sigma_loss: 0.0089 - y_mean_loss: 0.0129 - y_sigma_loss: 0.0012 - classification_loss: 0.0144\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.0992 - amplitude_loss: 0.0391 - x_mean_loss: 0.0251 - x_sigma_loss: 0.0086 - y_mean_loss: 0.0120 - y_sigma_loss: 0.0012 - classification_loss: 0.0132\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 0.0905 - amplitude_loss: 0.0353 - x_mean_loss: 0.0228 - x_sigma_loss: 0.0079 - y_mean_loss: 0.0117 - y_sigma_loss: 0.0011 - classification_loss: 0.0117\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.0876 - amplitude_loss: 0.0345 - x_mean_loss: 0.0222 - x_sigma_loss: 0.0076 - y_mean_loss: 0.0113 - y_sigma_loss: 0.0011 - classification_loss: 0.0108\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 6s 610us/step - loss: 0.0875 - amplitude_loss: 0.0376 - x_mean_loss: 0.0203 - x_sigma_loss: 0.0079 - y_mean_loss: 0.0109 - y_sigma_loss: 9.9642e-04 - classification_loss: 0.0100\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.0832 - amplitude_loss: 0.0352 - x_mean_loss: 0.0201 - x_sigma_loss: 0.0076 - y_mean_loss: 0.0100 - y_sigma_loss: 0.0010 - classification_loss: 0.0093\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.0738 - amplitude_loss: 0.0291 - x_mean_loss: 0.0188 - x_sigma_loss: 0.0067 - y_mean_loss: 0.0098 - y_sigma_loss: 9.3454e-04 - classification_loss: 0.0085\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.0661 - amplitude_loss: 0.0264 - x_mean_loss: 0.0166 - x_sigma_loss: 0.0061 - y_mean_loss: 0.0089 - y_sigma_loss: 8.9953e-04 - classification_loss: 0.0073\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.0674 - amplitude_loss: 0.0260 - x_mean_loss: 0.0174 - x_sigma_loss: 0.0064 - y_mean_loss: 0.0094 - y_sigma_loss: 9.6003e-04 - classification_loss: 0.0071\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.0644 - amplitude_loss: 0.0250 - x_mean_loss: 0.0177 - x_sigma_loss: 0.0058 - y_mean_loss: 0.0087 - y_sigma_loss: 9.3970e-04 - classification_loss: 0.0062\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.0610 - amplitude_loss: 0.0246 - x_mean_loss: 0.0156 - x_sigma_loss: 0.0056 - y_mean_loss: 0.0082 - y_sigma_loss: 7.5337e-04 - classification_loss: 0.0061\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 7s 709us/step - loss: 0.0565 - amplitude_loss: 0.0236 - x_mean_loss: 0.0138 - x_sigma_loss: 0.0056 - y_mean_loss: 0.0076 - y_sigma_loss: 7.9850e-04 - classification_loss: 0.0052\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 813us/step - loss: 0.0587 - amplitude_loss: 0.0257 - x_mean_loss: 0.0133 - x_sigma_loss: 0.0059 - y_mean_loss: 0.0078 - y_sigma_loss: 8.5032e-04 - classification_loss: 0.0053\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.0516 - amplitude_loss: 0.0217 - x_mean_loss: 0.0127 - x_sigma_loss: 0.0051 - y_mean_loss: 0.0071 - y_sigma_loss: 7.0265e-04 - classification_loss: 0.0044\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 0.0480 - amplitude_loss: 0.0190 - x_mean_loss: 0.0125 - x_sigma_loss: 0.0048 - y_mean_loss: 0.0072 - y_sigma_loss: 7.1358e-04 - classification_loss: 0.0038\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0493 - amplitude_loss: 0.0206 - x_mean_loss: 0.0129 - x_sigma_loss: 0.0049 - y_mean_loss: 0.0069 - y_sigma_loss: 6.8768e-04 - classification_loss: 0.0036\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.0468 - amplitude_loss: 0.0188 - x_mean_loss: 0.0124 - x_sigma_loss: 0.0047 - y_mean_loss: 0.0066 - y_sigma_loss: 6.8428e-04 - classification_loss: 0.0036\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 0.0459 - amplitude_loss: 0.0192 - x_mean_loss: 0.0112 - x_sigma_loss: 0.0047 - y_mean_loss: 0.0067 - y_sigma_loss: 6.6009e-04 - classification_loss: 0.0034\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 0.0403 - amplitude_loss: 0.0160 - x_mean_loss: 0.0102 - x_sigma_loss: 0.0041 - y_mean_loss: 0.0063 - y_sigma_loss: 6.1268e-04 - classification_loss: 0.0030\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.0394 - amplitude_loss: 0.0162 - x_mean_loss: 0.0094 - x_sigma_loss: 0.0041 - y_mean_loss: 0.0064 - y_sigma_loss: 6.3866e-04 - classification_loss: 0.0026\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.0410 - amplitude_loss: 0.0175 - x_mean_loss: 0.0094 - x_sigma_loss: 0.0044 - y_mean_loss: 0.0062 - y_sigma_loss: 7.0106e-04 - classification_loss: 0.0029\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 6s 595us/step - loss: 0.0413 - amplitude_loss: 0.0173 - x_mean_loss: 0.0105 - x_sigma_loss: 0.0042 - y_mean_loss: 0.0061 - y_sigma_loss: 6.4240e-04 - classification_loss: 0.0026\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.0404 - amplitude_loss: 0.0172 - x_mean_loss: 0.0103 - x_sigma_loss: 0.0042 - y_mean_loss: 0.0057 - y_sigma_loss: 6.5688e-04 - classification_loss: 0.0022\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 6s 610us/step - loss: 0.0356 - amplitude_loss: 0.0144 - x_mean_loss: 0.0089 - x_sigma_loss: 0.0037 - y_mean_loss: 0.0059 - y_sigma_loss: 5.8619e-04 - classification_loss: 0.0022\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 6s 598us/step - loss: 0.0362 - amplitude_loss: 0.0154 - x_mean_loss: 0.0089 - x_sigma_loss: 0.0038 - y_mean_loss: 0.0053 - y_sigma_loss: 5.7604e-04 - classification_loss: 0.0021\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 6s 614us/step - loss: 0.0375 - amplitude_loss: 0.0164 - x_mean_loss: 0.0089 - x_sigma_loss: 0.0040 - y_mean_loss: 0.0056 - y_sigma_loss: 6.4896e-04 - classification_loss: 0.0019\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.0358 - amplitude_loss: 0.0159 - x_mean_loss: 0.0084 - x_sigma_loss: 0.0037 - y_mean_loss: 0.0052 - y_sigma_loss: 6.4929e-04 - classification_loss: 0.0019\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.0315 - amplitude_loss: 0.0128 - x_mean_loss: 0.0081 - x_sigma_loss: 0.0034 - y_mean_loss: 0.0050 - y_sigma_loss: 5.4344e-04 - classification_loss: 0.0016\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.0284 - amplitude_loss: 0.0114 - x_mean_loss: 0.0073 - x_sigma_loss: 0.0030 - y_mean_loss: 0.0049 - y_sigma_loss: 5.1404e-04 - classification_loss: 0.0012\n",
      "\t Saved model /Users/thsyu/Software/ml_projects/cnn_gaussian/2d_gaussian/model_000_save.hdf5\n",
      "loss >#1: 0.760\n",
      "amplitude_loss >#1: 0.248\n",
      "x_mean_loss >#1: 0.159\n",
      "x_sigma_loss >#1: 0.045\n",
      "y_mean_loss >#1: 0.069\n",
      "y_sigma_loss >#1: 0.003\n",
      "classification_loss >#1: 0.241\n",
      "\n",
      " \n",
      " 1\n",
      "\t Hyperparameters:\n",
      "{'learning_rate': 0.0007, 'lr_decay': 1.0, 'num_epochs': 50, 'batch_size': 32, 'conv_filter_1': 32, 'conv_filter_2': 4, 'conv_kernel_1': 5, 'conv_kernel_2': 1, 'pool_kernel_1': 4, 'fc1_neurons': 512}\n",
      "\t Saved hyperparameters!\n",
      "\t Generated hyperparameters\n",
      "\t Generated dataset\n",
      "\t Creating model model_001\n",
      "\t Building model from hyperparameters...\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 3.3204 - amplitude_loss: 2.4829 - x_mean_loss: 0.2105 - x_sigma_loss: 0.2938 - y_mean_loss: 0.1335 - y_sigma_loss: 0.0448 - classification_loss: 0.1508\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.7421 - amplitude_loss: 0.3446 - x_mean_loss: 0.1397 - x_sigma_loss: 0.0586 - y_mean_loss: 0.0782 - y_sigma_loss: 0.0095 - classification_loss: 0.1116\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.6407 - amplitude_loss: 0.2935 - x_mean_loss: 0.1280 - x_sigma_loss: 0.0508 - y_mean_loss: 0.0675 - y_sigma_loss: 0.0068 - classification_loss: 0.0941\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.5550 - amplitude_loss: 0.2368 - x_mean_loss: 0.1238 - x_sigma_loss: 0.0415 - y_mean_loss: 0.0618 - y_sigma_loss: 0.0047 - classification_loss: 0.0865\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.5015 - amplitude_loss: 0.2027 - x_mean_loss: 0.1191 - x_sigma_loss: 0.0371 - y_mean_loss: 0.0567 - y_sigma_loss: 0.0047 - classification_loss: 0.0820\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.4715 - amplitude_loss: 0.1872 - x_mean_loss: 0.1144 - x_sigma_loss: 0.0348 - y_mean_loss: 0.0524 - y_sigma_loss: 0.0038 - classification_loss: 0.0790\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.4502 - amplitude_loss: 0.1761 - x_mean_loss: 0.1125 - x_sigma_loss: 0.0327 - y_mean_loss: 0.0498 - y_sigma_loss: 0.0032 - classification_loss: 0.0761\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.4310 - amplitude_loss: 0.1622 - x_mean_loss: 0.1117 - x_sigma_loss: 0.0306 - y_mean_loss: 0.0486 - y_sigma_loss: 0.0032 - classification_loss: 0.0746\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.4182 - amplitude_loss: 0.1595 - x_mean_loss: 0.1068 - x_sigma_loss: 0.0308 - y_mean_loss: 0.0456 - y_sigma_loss: 0.0029 - classification_loss: 0.0727\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.4070 - amplitude_loss: 0.1514 - x_mean_loss: 0.1078 - x_sigma_loss: 0.0292 - y_mean_loss: 0.0442 - y_sigma_loss: 0.0028 - classification_loss: 0.0714\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.4018 - amplitude_loss: 0.1503 - x_mean_loss: 0.1071 - x_sigma_loss: 0.0289 - y_mean_loss: 0.0436 - y_sigma_loss: 0.0026 - classification_loss: 0.0691\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.3934 - amplitude_loss: 0.1457 - x_mean_loss: 0.1063 - x_sigma_loss: 0.0278 - y_mean_loss: 0.0438 - y_sigma_loss: 0.0027 - classification_loss: 0.0673\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.3845 - amplitude_loss: 0.1411 - x_mean_loss: 0.1049 - x_sigma_loss: 0.0275 - y_mean_loss: 0.0429 - y_sigma_loss: 0.0025 - classification_loss: 0.0655\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.3705 - amplitude_loss: 0.1340 - x_mean_loss: 0.1026 - x_sigma_loss: 0.0262 - y_mean_loss: 0.0409 - y_sigma_loss: 0.0022 - classification_loss: 0.0642\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.3644 - amplitude_loss: 0.1321 - x_mean_loss: 0.1006 - x_sigma_loss: 0.0257 - y_mean_loss: 0.0420 - y_sigma_loss: 0.0023 - classification_loss: 0.0615\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.3565 - amplitude_loss: 0.1303 - x_mean_loss: 0.0994 - x_sigma_loss: 0.0249 - y_mean_loss: 0.0404 - y_sigma_loss: 0.0022 - classification_loss: 0.0597\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.3449 - amplitude_loss: 0.1222 - x_mean_loss: 0.0978 - x_sigma_loss: 0.0244 - y_mean_loss: 0.0397 - y_sigma_loss: 0.0021 - classification_loss: 0.0587\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.3426 - amplitude_loss: 0.1219 - x_mean_loss: 0.0994 - x_sigma_loss: 0.0232 - y_mean_loss: 0.0396 - y_sigma_loss: 0.0022 - classification_loss: 0.0570\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.3314 - amplitude_loss: 0.1187 - x_mean_loss: 0.0954 - x_sigma_loss: 0.0233 - y_mean_loss: 0.0376 - y_sigma_loss: 0.0021 - classification_loss: 0.0541\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.3224 - amplitude_loss: 0.1125 - x_mean_loss: 0.0948 - x_sigma_loss: 0.0225 - y_mean_loss: 0.0381 - y_sigma_loss: 0.0020 - classification_loss: 0.0527\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3127 - amplitude_loss: 0.1089 - x_mean_loss: 0.0933 - x_sigma_loss: 0.0215 - y_mean_loss: 0.0364 - y_sigma_loss: 0.0019 - classification_loss: 0.0511\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.3074 - amplitude_loss: 0.1076 - x_mean_loss: 0.0919 - x_sigma_loss: 0.0210 - y_mean_loss: 0.0362 - y_sigma_loss: 0.0019 - classification_loss: 0.0488\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.2943 - amplitude_loss: 0.1002 - x_mean_loss: 0.0912 - x_sigma_loss: 0.0204 - y_mean_loss: 0.0346 - y_sigma_loss: 0.0018 - classification_loss: 0.0460\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.2859 - amplitude_loss: 0.0986 - x_mean_loss: 0.0864 - x_sigma_loss: 0.0197 - y_mean_loss: 0.0341 - y_sigma_loss: 0.0020 - classification_loss: 0.0452\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.2804 - amplitude_loss: 0.0968 - x_mean_loss: 0.0850 - x_sigma_loss: 0.0197 - y_mean_loss: 0.0333 - y_sigma_loss: 0.0018 - classification_loss: 0.0440\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.2691 - amplitude_loss: 0.0911 - x_mean_loss: 0.0832 - x_sigma_loss: 0.0186 - y_mean_loss: 0.0323 - y_sigma_loss: 0.0017 - classification_loss: 0.0420\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.2597 - amplitude_loss: 0.0882 - x_mean_loss: 0.0773 - x_sigma_loss: 0.0184 - y_mean_loss: 0.0328 - y_sigma_loss: 0.0019 - classification_loss: 0.0409\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.2512 - amplitude_loss: 0.0834 - x_mean_loss: 0.0785 - x_sigma_loss: 0.0177 - y_mean_loss: 0.0312 - y_sigma_loss: 0.0018 - classification_loss: 0.0387\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 5s 465us/step - loss: 0.2395 - amplitude_loss: 0.0797 - x_mean_loss: 0.0752 - x_sigma_loss: 0.0168 - y_mean_loss: 0.0294 - y_sigma_loss: 0.0017 - classification_loss: 0.0367\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.2377 - amplitude_loss: 0.0794 - x_mean_loss: 0.0746 - x_sigma_loss: 0.0167 - y_mean_loss: 0.0289 - y_sigma_loss: 0.0017 - classification_loss: 0.0363\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.2200 - amplitude_loss: 0.0706 - x_mean_loss: 0.0708 - x_sigma_loss: 0.0157 - y_mean_loss: 0.0278 - y_sigma_loss: 0.0017 - classification_loss: 0.0334\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.2166 - amplitude_loss: 0.0709 - x_mean_loss: 0.0697 - x_sigma_loss: 0.0152 - y_mean_loss: 0.0266 - y_sigma_loss: 0.0016 - classification_loss: 0.0329\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 5s 466us/step - loss: 0.2044 - amplitude_loss: 0.0674 - x_mean_loss: 0.0651 - x_sigma_loss: 0.0148 - y_mean_loss: 0.0252 - y_sigma_loss: 0.0015 - classification_loss: 0.0304\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.1970 - amplitude_loss: 0.0639 - x_mean_loss: 0.0631 - x_sigma_loss: 0.0139 - y_mean_loss: 0.0247 - y_sigma_loss: 0.0015 - classification_loss: 0.0298\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 5s 465us/step - loss: 0.1944 - amplitude_loss: 0.0629 - x_mean_loss: 0.0612 - x_sigma_loss: 0.0141 - y_mean_loss: 0.0251 - y_sigma_loss: 0.0015 - classification_loss: 0.0297\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.1852 - amplitude_loss: 0.0602 - x_mean_loss: 0.0594 - x_sigma_loss: 0.0134 - y_mean_loss: 0.0235 - y_sigma_loss: 0.0014 - classification_loss: 0.0274\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.1811 - amplitude_loss: 0.0586 - x_mean_loss: 0.0583 - x_sigma_loss: 0.0133 - y_mean_loss: 0.0239 - y_sigma_loss: 0.0015 - classification_loss: 0.0255\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.1750 - amplitude_loss: 0.0575 - x_mean_loss: 0.0564 - x_sigma_loss: 0.0128 - y_mean_loss: 0.0221 - y_sigma_loss: 0.0014 - classification_loss: 0.0249\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.1683 - amplitude_loss: 0.0551 - x_mean_loss: 0.0537 - x_sigma_loss: 0.0129 - y_mean_loss: 0.0218 - y_sigma_loss: 0.0013 - classification_loss: 0.0236\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.1692 - amplitude_loss: 0.0584 - x_mean_loss: 0.0527 - x_sigma_loss: 0.0129 - y_mean_loss: 0.0216 - y_sigma_loss: 0.0014 - classification_loss: 0.0222\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.1552 - amplitude_loss: 0.0506 - x_mean_loss: 0.0501 - x_sigma_loss: 0.0115 - y_mean_loss: 0.0205 - y_sigma_loss: 0.0014 - classification_loss: 0.0211\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.1562 - amplitude_loss: 0.0531 - x_mean_loss: 0.0493 - x_sigma_loss: 0.0119 - y_mean_loss: 0.0202 - y_sigma_loss: 0.0013 - classification_loss: 0.0203\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.1471 - amplitude_loss: 0.0473 - x_mean_loss: 0.0473 - x_sigma_loss: 0.0114 - y_mean_loss: 0.0195 - y_sigma_loss: 0.0013 - classification_loss: 0.0204\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.1448 - amplitude_loss: 0.0470 - x_mean_loss: 0.0479 - x_sigma_loss: 0.0113 - y_mean_loss: 0.0189 - y_sigma_loss: 0.0013 - classification_loss: 0.0183\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.1448 - amplitude_loss: 0.0500 - x_mean_loss: 0.0450 - x_sigma_loss: 0.0115 - y_mean_loss: 0.0188 - y_sigma_loss: 0.0014 - classification_loss: 0.0183\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.1335 - amplitude_loss: 0.0434 - x_mean_loss: 0.0433 - x_sigma_loss: 0.0104 - y_mean_loss: 0.0180 - y_sigma_loss: 0.0012 - classification_loss: 0.0171\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.1268 - amplitude_loss: 0.0405 - x_mean_loss: 0.0413 - x_sigma_loss: 0.0099 - y_mean_loss: 0.0178 - y_sigma_loss: 0.0012 - classification_loss: 0.0164\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.1250 - amplitude_loss: 0.0398 - x_mean_loss: 0.0410 - x_sigma_loss: 0.0099 - y_mean_loss: 0.0172 - y_sigma_loss: 0.0013 - classification_loss: 0.0157\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.1236 - amplitude_loss: 0.0393 - x_mean_loss: 0.0414 - x_sigma_loss: 0.0099 - y_mean_loss: 0.0170 - y_sigma_loss: 0.0012 - classification_loss: 0.0148\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.1205 - amplitude_loss: 0.0396 - x_mean_loss: 0.0388 - x_sigma_loss: 0.0095 - y_mean_loss: 0.0173 - y_sigma_loss: 0.0012 - classification_loss: 0.0143\n",
      "\t Saved model /Users/thsyu/Software/ml_projects/cnn_gaussian/2d_gaussian/model_001_save.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss >#1: 0.591\n",
      "amplitude_loss >#1: 0.183\n",
      "x_mean_loss >#1: 0.172\n",
      "x_sigma_loss >#1: 0.035\n",
      "y_mean_loss >#1: 0.065\n",
      "y_sigma_loss >#1: 0.002\n",
      "classification_loss >#1: 0.129\n",
      "\n",
      " \n",
      " 2\n",
      "\t Hyperparameters:\n",
      "{'learning_rate': 0.01, 'lr_decay': 1.0, 'num_epochs': 80, 'batch_size': 128, 'conv_filter_1': 4, 'conv_filter_2': 8, 'conv_kernel_1': 5, 'conv_kernel_2': 2, 'pool_kernel_1': 5, 'fc1_neurons': 256}\n",
      "\t Saved hyperparameters!\n",
      "\t Generated hyperparameters\n",
      "\t Generated dataset\n",
      "\t Creating model model_002\n",
      "\t Building model from hyperparameters...\n",
      "Epoch 1/80\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 6.3735 - amplitude_loss: 4.7332 - x_mean_loss: 0.4740 - x_sigma_loss: 0.4306 - y_mean_loss: 0.2522 - y_sigma_loss: 0.3021 - classification_loss: 0.1720\n",
      "Epoch 2/80\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.7636 - amplitude_loss: 0.3535 - x_mean_loss: 0.1527 - x_sigma_loss: 0.0615 - y_mean_loss: 0.0782 - y_sigma_loss: 0.0088 - classification_loss: 0.1084\n",
      "Epoch 3/80\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.6679 - amplitude_loss: 0.2966 - x_mean_loss: 0.1387 - x_sigma_loss: 0.0555 - y_mean_loss: 0.0736 - y_sigma_loss: 0.0067 - classification_loss: 0.0960\n",
      "Epoch 4/80\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.6365 - amplitude_loss: 0.2838 - x_mean_loss: 0.1349 - x_sigma_loss: 0.0528 - y_mean_loss: 0.0682 - y_sigma_loss: 0.0053 - classification_loss: 0.0910\n",
      "Epoch 5/80\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.5937 - amplitude_loss: 0.2529 - x_mean_loss: 0.1335 - x_sigma_loss: 0.0486 - y_mean_loss: 0.0665 - y_sigma_loss: 0.0048 - classification_loss: 0.0873\n",
      "Epoch 6/80\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.5631 - amplitude_loss: 0.2312 - x_mean_loss: 0.1307 - x_sigma_loss: 0.0452 - y_mean_loss: 0.0650 - y_sigma_loss: 0.0043 - classification_loss: 0.0864\n",
      "Epoch 7/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.5333 - amplitude_loss: 0.2109 - x_mean_loss: 0.1290 - x_sigma_loss: 0.0427 - y_mean_loss: 0.0618 - y_sigma_loss: 0.0042 - classification_loss: 0.0844\n",
      "Epoch 8/80\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.5159 - amplitude_loss: 0.1985 - x_mean_loss: 0.1304 - x_sigma_loss: 0.0409 - y_mean_loss: 0.0587 - y_sigma_loss: 0.0042 - classification_loss: 0.0832\n",
      "Epoch 9/80\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.4961 - amplitude_loss: 0.1883 - x_mean_loss: 0.1254 - x_sigma_loss: 0.0394 - y_mean_loss: 0.0583 - y_sigma_loss: 0.0039 - classification_loss: 0.0811\n",
      "Epoch 10/80\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.4736 - amplitude_loss: 0.1737 - x_mean_loss: 0.1238 - x_sigma_loss: 0.0360 - y_mean_loss: 0.0565 - y_sigma_loss: 0.0033 - classification_loss: 0.0803\n",
      "Epoch 11/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.4735 - amplitude_loss: 0.1748 - x_mean_loss: 0.1235 - x_sigma_loss: 0.0361 - y_mean_loss: 0.0551 - y_sigma_loss: 0.0034 - classification_loss: 0.0805\n",
      "Epoch 12/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.4532 - amplitude_loss: 0.1653 - x_mean_loss: 0.1215 - x_sigma_loss: 0.0343 - y_mean_loss: 0.0527 - y_sigma_loss: 0.0031 - classification_loss: 0.07662s - loss: 0.4459 - amplitude_loss: 0.1540 - x_mean_loss: \n",
      "Epoch 13/80\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.4498 - amplitude_loss: 0.1621 - x_mean_loss: 0.1212 - x_sigma_loss: 0.0339 - y_mean_loss: 0.0522 - y_sigma_loss: 0.0031 - classification_loss: 0.0769\n",
      "Epoch 14/80\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.4578 - amplitude_loss: 0.1692 - x_mean_loss: 0.1200 - x_sigma_loss: 0.0357 - y_mean_loss: 0.0502 - y_sigma_loss: 0.0034 - classification_loss: 0.0791\n",
      "Epoch 15/80\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.4565 - amplitude_loss: 0.1690 - x_mean_loss: 0.1210 - x_sigma_loss: 0.0371 - y_mean_loss: 0.0495 - y_sigma_loss: 0.0040 - classification_loss: 0.0761\n",
      "Epoch 16/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.4491 - amplitude_loss: 0.1658 - x_mean_loss: 0.1179 - x_sigma_loss: 0.0360 - y_mean_loss: 0.0494 - y_sigma_loss: 0.0035 - classification_loss: 0.0766\n",
      "Epoch 17/80\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.4391 - amplitude_loss: 0.1602 - x_mean_loss: 0.1184 - x_sigma_loss: 0.0338 - y_mean_loss: 0.0487 - y_sigma_loss: 0.0030 - classification_loss: 0.0754\n",
      "Epoch 18/80\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.4391 - amplitude_loss: 0.1586 - x_mean_loss: 0.1181 - x_sigma_loss: 0.0330 - y_mean_loss: 0.0495 - y_sigma_loss: 0.0030 - classification_loss: 0.0772\n",
      "Epoch 19/80\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.4442 - amplitude_loss: 0.1623 - x_mean_loss: 0.1182 - x_sigma_loss: 0.0345 - y_mean_loss: 0.0478 - y_sigma_loss: 0.0030 - classification_loss: 0.0788\n",
      "Epoch 20/80\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.4348 - amplitude_loss: 0.1570 - x_mean_loss: 0.1174 - x_sigma_loss: 0.0331 - y_mean_loss: 0.0466 - y_sigma_loss: 0.0031 - classification_loss: 0.0776\n",
      "Epoch 21/80\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.4399 - amplitude_loss: 0.1623 - x_mean_loss: 0.1173 - x_sigma_loss: 0.0346 - y_mean_loss: 0.0463 - y_sigma_loss: 0.0033 - classification_loss: 0.0761\n",
      "Epoch 22/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.4398 - amplitude_loss: 0.1618 - x_mean_loss: 0.1173 - x_sigma_loss: 0.0342 - y_mean_loss: 0.0466 - y_sigma_loss: 0.0032 - classification_loss: 0.0766\n",
      "Epoch 23/80\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.4237 - amplitude_loss: 0.1545 - x_mean_loss: 0.1147 - x_sigma_loss: 0.0325 - y_mean_loss: 0.0451 - y_sigma_loss: 0.0029 - classification_loss: 0.0738\n",
      "Epoch 24/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.4310 - amplitude_loss: 0.1574 - x_mean_loss: 0.1155 - x_sigma_loss: 0.0332 - y_mean_loss: 0.0472 - y_sigma_loss: 0.0031 - classification_loss: 0.0746\n",
      "Epoch 25/80\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.4088 - amplitude_loss: 0.1450 - x_mean_loss: 0.1152 - x_sigma_loss: 0.0304 - y_mean_loss: 0.0448 - y_sigma_loss: 0.0027 - classification_loss: 0.0704\n",
      "Epoch 26/80\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.4184 - amplitude_loss: 0.1516 - x_mean_loss: 0.1145 - x_sigma_loss: 0.0320 - y_mean_loss: 0.0459 - y_sigma_loss: 0.0030 - classification_loss: 0.0715\n",
      "Epoch 27/80\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.4160 - amplitude_loss: 0.1514 - x_mean_loss: 0.1126 - x_sigma_loss: 0.0317 - y_mean_loss: 0.0457 - y_sigma_loss: 0.0028 - classification_loss: 0.0719\n",
      "Epoch 28/80\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.4096 - amplitude_loss: 0.1470 - x_mean_loss: 0.1146 - x_sigma_loss: 0.0307 - y_mean_loss: 0.0451 - y_sigma_loss: 0.0025 - classification_loss: 0.0702\n",
      "Epoch 29/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.4107 - amplitude_loss: 0.1468 - x_mean_loss: 0.1135 - x_sigma_loss: 0.0314 - y_mean_loss: 0.0460 - y_sigma_loss: 0.0031 - classification_loss: 0.0696\n",
      "Epoch 30/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.4073 - amplitude_loss: 0.1485 - x_mean_loss: 0.1124 - x_sigma_loss: 0.0314 - y_mean_loss: 0.0441 - y_sigma_loss: 0.0029 - classification_loss: 0.0678\n",
      "Epoch 31/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.4009 - amplitude_loss: 0.1437 - x_mean_loss: 0.1123 - x_sigma_loss: 0.0311 - y_mean_loss: 0.0442 - y_sigma_loss: 0.0030 - classification_loss: 0.0667\n",
      "Epoch 32/80\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3791 - amplitude_loss: 0.1329 - x_mean_loss: 0.1083 - x_sigma_loss: 0.0281 - y_mean_loss: 0.0432 - y_sigma_loss: 0.0023 - classification_loss: 0.0642\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.3840 - amplitude_loss: 0.1349 - x_mean_loss: 0.1117 - x_sigma_loss: 0.0287 - y_mean_loss: 0.0419 - y_sigma_loss: 0.0026 - classification_loss: 0.0645\n",
      "Epoch 34/80\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3772 - amplitude_loss: 0.1359 - x_mean_loss: 0.1076 - x_sigma_loss: 0.0290 - y_mean_loss: 0.0422 - y_sigma_loss: 0.0026 - classification_loss: 0.0605\n",
      "Epoch 35/80\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3587 - amplitude_loss: 0.1238 - x_mean_loss: 0.1051 - x_sigma_loss: 0.0269 - y_mean_loss: 0.0423 - y_sigma_loss: 0.0024 - classification_loss: 0.0581\n",
      "Epoch 36/80\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3498 - amplitude_loss: 0.1225 - x_mean_loss: 0.1028 - x_sigma_loss: 0.0269 - y_mean_loss: 0.0412 - y_sigma_loss: 0.0023 - classification_loss: 0.0543\n",
      "Epoch 37/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.3372 - amplitude_loss: 0.1164 - x_mean_loss: 0.1020 - x_sigma_loss: 0.0259 - y_mean_loss: 0.0401 - y_sigma_loss: 0.0023 - classification_loss: 0.0506\n",
      "Epoch 38/80\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.3326 - amplitude_loss: 0.1174 - x_mean_loss: 0.1001 - x_sigma_loss: 0.0258 - y_mean_loss: 0.0394 - y_sigma_loss: 0.0023 - classification_loss: 0.0492\n",
      "Epoch 39/80\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.3276 - amplitude_loss: 0.1150 - x_mean_loss: 0.0983 - x_sigma_loss: 0.0264 - y_mean_loss: 0.0388 - y_sigma_loss: 0.0027 - classification_loss: 0.0467\n",
      "Epoch 40/80\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.3155 - amplitude_loss: 0.1080 - x_mean_loss: 0.0983 - x_sigma_loss: 0.0243 - y_mean_loss: 0.0378 - y_sigma_loss: 0.0023 - classification_loss: 0.0452\n",
      "Epoch 41/80\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.3271 - amplitude_loss: 0.1167 - x_mean_loss: 0.0991 - x_sigma_loss: 0.0260 - y_mean_loss: 0.0383 - y_sigma_loss: 0.0024 - classification_loss: 0.0451\n",
      "Epoch 42/80\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3015 - amplitude_loss: 0.1057 - x_mean_loss: 0.0940 - x_sigma_loss: 0.0246 - y_mean_loss: 0.0365 - y_sigma_loss: 0.0024 - classification_loss: 0.0381\n",
      "Epoch 43/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2788 - amplitude_loss: 0.0938 - x_mean_loss: 0.0915 - x_sigma_loss: 0.0223 - y_mean_loss: 0.0343 - y_sigma_loss: 0.0021 - classification_loss: 0.0349\n",
      "Epoch 44/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2683 - amplitude_loss: 0.0894 - x_mean_loss: 0.0900 - x_sigma_loss: 0.0212 - y_mean_loss: 0.0332 - y_sigma_loss: 0.0020 - classification_loss: 0.0329\n",
      "Epoch 45/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2621 - amplitude_loss: 0.0858 - x_mean_loss: 0.0888 - x_sigma_loss: 0.0211 - y_mean_loss: 0.0326 - y_sigma_loss: 0.0021 - classification_loss: 0.0317\n",
      "Epoch 46/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.2561 - amplitude_loss: 0.0844 - x_mean_loss: 0.0874 - x_sigma_loss: 0.0208 - y_mean_loss: 0.0321 - y_sigma_loss: 0.0021 - classification_loss: 0.0291\n",
      "Epoch 47/80\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.2484 - amplitude_loss: 0.0811 - x_mean_loss: 0.0852 - x_sigma_loss: 0.0199 - y_mean_loss: 0.0319 - y_sigma_loss: 0.0020 - classification_loss: 0.0282\n",
      "Epoch 48/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.2468 - amplitude_loss: 0.0815 - x_mean_loss: 0.0830 - x_sigma_loss: 0.0205 - y_mean_loss: 0.0320 - y_sigma_loss: 0.0022 - classification_loss: 0.0274\n",
      "Epoch 49/80\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2362 - amplitude_loss: 0.0771 - x_mean_loss: 0.0834 - x_sigma_loss: 0.0192 - y_mean_loss: 0.0302 - y_sigma_loss: 0.0020 - classification_loss: 0.0244\n",
      "Epoch 50/80\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.2362 - amplitude_loss: 0.0768 - x_mean_loss: 0.0831 - x_sigma_loss: 0.0193 - y_mean_loss: 0.0308 - y_sigma_loss: 0.0019 - classification_loss: 0.0243\n",
      "Epoch 51/80\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.2227 - amplitude_loss: 0.0724 - x_mean_loss: 0.0782 - x_sigma_loss: 0.0186 - y_mean_loss: 0.0300 - y_sigma_loss: 0.0019 - classification_loss: 0.0215\n",
      "Epoch 52/80\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.2166 - amplitude_loss: 0.0700 - x_mean_loss: 0.0768 - x_sigma_loss: 0.0180 - y_mean_loss: 0.0288 - y_sigma_loss: 0.0019 - classification_loss: 0.0211\n",
      "Epoch 53/80\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.2183 - amplitude_loss: 0.0720 - x_mean_loss: 0.0769 - x_sigma_loss: 0.0188 - y_mean_loss: 0.0290 - y_sigma_loss: 0.0021 - classification_loss: 0.0195\n",
      "Epoch 54/80\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.2114 - amplitude_loss: 0.0691 - x_mean_loss: 0.0748 - x_sigma_loss: 0.0186 - y_mean_loss: 0.0280 - y_sigma_loss: 0.0020 - classification_loss: 0.0189\n",
      "Epoch 55/80\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2032 - amplitude_loss: 0.0656 - x_mean_loss: 0.0725 - x_sigma_loss: 0.0171 - y_mean_loss: 0.0274 - y_sigma_loss: 0.0017 - classification_loss: 0.0189\n",
      "Epoch 56/80\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.2026 - amplitude_loss: 0.0654 - x_mean_loss: 0.0721 - x_sigma_loss: 0.0175 - y_mean_loss: 0.0273 - y_sigma_loss: 0.0020 - classification_loss: 0.0184\n",
      "Epoch 57/80\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.2020 - amplitude_loss: 0.0667 - x_mean_loss: 0.0719 - x_sigma_loss: 0.0180 - y_mean_loss: 0.0270 - y_sigma_loss: 0.0021 - classification_loss: 0.0164\n",
      "Epoch 58/80\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.2003 - amplitude_loss: 0.0652 - x_mean_loss: 0.0711 - x_sigma_loss: 0.0174 - y_mean_loss: 0.0274 - y_sigma_loss: 0.0018 - classification_loss: 0.0171\n",
      "Epoch 59/80\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.1921 - amplitude_loss: 0.0611 - x_mean_loss: 0.0702 - x_sigma_loss: 0.0170 - y_mean_loss: 0.0261 - y_sigma_loss: 0.0019 - classification_loss: 0.0158\n",
      "Epoch 60/80\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.1871 - amplitude_loss: 0.0606 - x_mean_loss: 0.0681 - x_sigma_loss: 0.0165 - y_mean_loss: 0.0257 - y_sigma_loss: 0.0018 - classification_loss: 0.0143\n",
      "Epoch 61/80\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.1826 - amplitude_loss: 0.0573 - x_mean_loss: 0.0665 - x_sigma_loss: 0.0159 - y_mean_loss: 0.0265 - y_sigma_loss: 0.0017 - classification_loss: 0.0147\n",
      "Epoch 62/80\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.1787 - amplitude_loss: 0.0560 - x_mean_loss: 0.0677 - x_sigma_loss: 0.0157 - y_mean_loss: 0.0245 - y_sigma_loss: 0.0017 - classification_loss: 0.0132\n",
      "Epoch 63/80\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.1750 - amplitude_loss: 0.0550 - x_mean_loss: 0.0655 - x_sigma_loss: 0.0154 - y_mean_loss: 0.0248 - y_sigma_loss: 0.0017 - classification_loss: 0.0127\n",
      "Epoch 64/80\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.1729 - amplitude_loss: 0.0554 - x_mean_loss: 0.0641 - x_sigma_loss: 0.0156 - y_mean_loss: 0.0244 - y_sigma_loss: 0.0017 - classification_loss: 0.0117\n",
      "Epoch 65/80\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.1770 - amplitude_loss: 0.0569 - x_mean_loss: 0.0646 - x_sigma_loss: 0.0157 - y_mean_loss: 0.0254 - y_sigma_loss: 0.0018 - classification_loss: 0.0125\n",
      "Epoch 66/80\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.1776 - amplitude_loss: 0.0570 - x_mean_loss: 0.0653 - x_sigma_loss: 0.0159 - y_mean_loss: 0.0250 - y_sigma_loss: 0.0018 - classification_loss: 0.0129\n",
      "Epoch 67/80\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.1729 - amplitude_loss: 0.0554 - x_mean_loss: 0.0639 - x_sigma_loss: 0.0154 - y_mean_loss: 0.0242 - y_sigma_loss: 0.0017 - classification_loss: 0.0126\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.1648 - amplitude_loss: 0.0518 - x_mean_loss: 0.0621 - x_sigma_loss: 0.0149 - y_mean_loss: 0.0232 - y_sigma_loss: 0.0016 - classification_loss: 0.0111\n",
      "Epoch 69/80\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.1632 - amplitude_loss: 0.0512 - x_mean_loss: 0.0605 - x_sigma_loss: 0.0149 - y_mean_loss: 0.0236 - y_sigma_loss: 0.0017 - classification_loss: 0.01135s - loss: 0.1478 - amplit\n",
      "Epoch 70/80\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.1655 - amplitude_loss: 0.0530 - x_mean_loss: 0.0618 - x_sigma_loss: 0.0149 - y_mean_loss: 0.0232 - y_sigma_loss: 0.0017 - classification_loss: 0.0111\n",
      "Epoch 71/80\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.1651 - amplitude_loss: 0.0523 - x_mean_loss: 0.0623 - x_sigma_loss: 0.0149 - y_mean_loss: 0.0232 - y_sigma_loss: 0.0017 - classification_loss: 0.0106\n",
      "Epoch 72/80\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.1565 - amplitude_loss: 0.0507 - x_mean_loss: 0.0585 - x_sigma_loss: 0.0146 - y_mean_loss: 0.0223 - y_sigma_loss: 0.0017 - classification_loss: 0.0088\n",
      "Epoch 73/80\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.1513 - amplitude_loss: 0.0475 - x_mean_loss: 0.0574 - x_sigma_loss: 0.0139 - y_mean_loss: 0.0217 - y_sigma_loss: 0.0015 - classification_loss: 0.0094\n",
      "Epoch 74/80\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.1526 - amplitude_loss: 0.0477 - x_mean_loss: 0.0576 - x_sigma_loss: 0.0141 - y_mean_loss: 0.0220 - y_sigma_loss: 0.0017 - classification_loss: 0.0094\n",
      "Epoch 75/80\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1581 - amplitude_loss: 0.0509 - x_mean_loss: 0.0590 - x_sigma_loss: 0.0150 - y_mean_loss: 0.0226 - y_sigma_loss: 0.0018 - classification_loss: 0.0088\n",
      "Epoch 76/80\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.1495 - amplitude_loss: 0.0472 - x_mean_loss: 0.0565 - x_sigma_loss: 0.0141 - y_mean_loss: 0.0213 - y_sigma_loss: 0.0016 - classification_loss: 0.0088\n",
      "Epoch 77/80\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.1457 - amplitude_loss: 0.0458 - x_mean_loss: 0.0563 - x_sigma_loss: 0.0136 - y_mean_loss: 0.0207 - y_sigma_loss: 0.0014 - classification_loss: 0.0079\n",
      "Epoch 78/80\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.1458 - amplitude_loss: 0.0452 - x_mean_loss: 0.0561 - x_sigma_loss: 0.0135 - y_mean_loss: 0.0216 - y_sigma_loss: 0.0016 - classification_loss: 0.0080\n",
      "Epoch 79/80\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.1448 - amplitude_loss: 0.0459 - x_mean_loss: 0.0552 - x_sigma_loss: 0.0136 - y_mean_loss: 0.0209 - y_sigma_loss: 0.0016 - classification_loss: 0.0078\n",
      "Epoch 80/80\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.1439 - amplitude_loss: 0.0445 - x_mean_loss: 0.0554 - x_sigma_loss: 0.0133 - y_mean_loss: 0.0212 - y_sigma_loss: 0.0015 - classification_loss: 0.0081\n",
      "\t Saved model /Users/thsyu/Software/ml_projects/cnn_gaussian/2d_gaussian/model_002_save.hdf5\n",
      "loss >#1: 0.725\n",
      "amplitude_loss >#1: 0.206\n",
      "x_mean_loss >#1: 0.168\n",
      "x_sigma_loss >#1: 0.043\n",
      "y_mean_loss >#1: 0.067\n",
      "y_sigma_loss >#1: 0.003\n",
      "classification_loss >#1: 0.233\n",
      "\n",
      " \n",
      " 3\n",
      "\t Hyperparameters:\n",
      "{'learning_rate': 0.003, 'lr_decay': 1.0, 'num_epochs': 30, 'batch_size': 64, 'conv_filter_1': 32, 'conv_filter_2': 8, 'conv_kernel_1': 5, 'conv_kernel_2': 1, 'pool_kernel_1': 3, 'fc1_neurons': 256}\n",
      "\t Saved hyperparameters!\n",
      "\t Generated hyperparameters\n",
      "\t Generated dataset\n",
      "\t Creating model model_003\n",
      "\t Building model from hyperparameters...\n",
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 2.0738 - amplitude_loss: 1.3941 - x_mean_loss: 0.1969 - x_sigma_loss: 0.1516 - y_mean_loss: 0.1043 - y_sigma_loss: 0.1002 - classification_loss: 0.1245\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.6219 - amplitude_loss: 0.2794 - x_mean_loss: 0.1391 - x_sigma_loss: 0.0494 - y_mean_loss: 0.0602 - y_sigma_loss: 0.0069 - classification_loss: 0.0869\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.5627 - amplitude_loss: 0.2513 - x_mean_loss: 0.1296 - x_sigma_loss: 0.0434 - y_mean_loss: 0.0535 - y_sigma_loss: 0.0050 - classification_loss: 0.0797\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.4974 - amplitude_loss: 0.2096 - x_mean_loss: 0.1213 - x_sigma_loss: 0.0379 - y_mean_loss: 0.0500 - y_sigma_loss: 0.0040 - classification_loss: 0.0743\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.4654 - amplitude_loss: 0.1867 - x_mean_loss: 0.1216 - x_sigma_loss: 0.0347 - y_mean_loss: 0.0480 - y_sigma_loss: 0.0033 - classification_loss: 0.0706\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.4320 - amplitude_loss: 0.1737 - x_mean_loss: 0.1111 - x_sigma_loss: 0.0321 - y_mean_loss: 0.0451 - y_sigma_loss: 0.0031 - classification_loss: 0.0671\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.4226 - amplitude_loss: 0.1692 - x_mean_loss: 0.1137 - x_sigma_loss: 0.0310 - y_mean_loss: 0.0433 - y_sigma_loss: 0.0031 - classification_loss: 0.0621\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.4169 - amplitude_loss: 0.1692 - x_mean_loss: 0.1118 - x_sigma_loss: 0.0313 - y_mean_loss: 0.0435 - y_sigma_loss: 0.0029 - classification_loss: 0.0580\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.3873 - amplitude_loss: 0.1523 - x_mean_loss: 0.1079 - x_sigma_loss: 0.0288 - y_mean_loss: 0.0427 - y_sigma_loss: 0.0027 - classification_loss: 0.0531\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.3670 - amplitude_loss: 0.1427 - x_mean_loss: 0.1017 - x_sigma_loss: 0.0274 - y_mean_loss: 0.0406 - y_sigma_loss: 0.0028 - classification_loss: 0.0517\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3596 - amplitude_loss: 0.1426 - x_mean_loss: 0.1009 - x_sigma_loss: 0.0268 - y_mean_loss: 0.0380 - y_sigma_loss: 0.0026 - classification_loss: 0.04841s - loss: 0.3478 - amplitude_loss: 0.1346 - x_mean_loss: 0.0993 - x_sigma_loss: 0.0263 - y_mean_loss: 0.0373 - y_si\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.3498 - amplitude_loss: 0.1388 - x_mean_loss: 0.0982 - x_sigma_loss: 0.0264 - y_mean_loss: 0.0376 - y_sigma_loss: 0.0029 - classification_loss: 0.0458\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.3166 - amplitude_loss: 0.1217 - x_mean_loss: 0.0927 - x_sigma_loss: 0.0241 - y_mean_loss: 0.0363 - y_sigma_loss: 0.0027 - classification_loss: 0.0390\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.3160 - amplitude_loss: 0.1245 - x_mean_loss: 0.0903 - x_sigma_loss: 0.0241 - y_mean_loss: 0.0365 - y_sigma_loss: 0.0024 - classification_loss: 0.0382\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2957 - amplitude_loss: 0.1147 - x_mean_loss: 0.0882 - x_sigma_loss: 0.0223 - y_mean_loss: 0.0343 - y_sigma_loss: 0.0023 - classification_loss: 0.0338\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.2775 - amplitude_loss: 0.1091 - x_mean_loss: 0.0817 - x_sigma_loss: 0.0215 - y_mean_loss: 0.0330 - y_sigma_loss: 0.0024 - classification_loss: 0.0298\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2661 - amplitude_loss: 0.1026 - x_mean_loss: 0.0796 - x_sigma_loss: 0.0207 - y_mean_loss: 0.0322 - y_sigma_loss: 0.0021 - classification_loss: 0.0287\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2709 - amplitude_loss: 0.1080 - x_mean_loss: 0.0786 - x_sigma_loss: 0.0212 - y_mean_loss: 0.0326 - y_sigma_loss: 0.0020 - classification_loss: 0.0283\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.2469 - amplitude_loss: 0.0959 - x_mean_loss: 0.0759 - x_sigma_loss: 0.0195 - y_mean_loss: 0.0306 - y_sigma_loss: 0.0023 - classification_loss: 0.0229\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.2276 - amplitude_loss: 0.0881 - x_mean_loss: 0.0695 - x_sigma_loss: 0.0183 - y_mean_loss: 0.0302 - y_sigma_loss: 0.0019 - classification_loss: 0.0195\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2223 - amplitude_loss: 0.0870 - x_mean_loss: 0.0677 - x_sigma_loss: 0.0176 - y_mean_loss: 0.0295 - y_sigma_loss: 0.0018 - classification_loss: 0.0190\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2094 - amplitude_loss: 0.0807 - x_mean_loss: 0.0650 - x_sigma_loss: 0.0167 - y_mean_loss: 0.0276 - y_sigma_loss: 0.0019 - classification_loss: 0.0174\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.1946 - amplitude_loss: 0.0741 - x_mean_loss: 0.0608 - x_sigma_loss: 0.0162 - y_mean_loss: 0.0264 - y_sigma_loss: 0.0019 - classification_loss: 0.0154\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.1892 - amplitude_loss: 0.0734 - x_mean_loss: 0.0578 - x_sigma_loss: 0.0155 - y_mean_loss: 0.0264 - y_sigma_loss: 0.0017 - classification_loss: 0.0143\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.1762 - amplitude_loss: 0.0689 - x_mean_loss: 0.0555 - x_sigma_loss: 0.0147 - y_mean_loss: 0.0242 - y_sigma_loss: 0.0017 - classification_loss: 0.0112\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.1716 - amplitude_loss: 0.0660 - x_mean_loss: 0.0544 - x_sigma_loss: 0.0144 - y_mean_loss: 0.0247 - y_sigma_loss: 0.0018 - classification_loss: 0.0107\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.1568 - amplitude_loss: 0.0602 - x_mean_loss: 0.0501 - x_sigma_loss: 0.0129 - y_mean_loss: 0.0234 - y_sigma_loss: 0.0014 - classification_loss: 0.0088\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.1504 - amplitude_loss: 0.0571 - x_mean_loss: 0.0480 - x_sigma_loss: 0.0128 - y_mean_loss: 0.0224 - y_sigma_loss: 0.0015 - classification_loss: 0.0088\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.1460 - amplitude_loss: 0.0590 - x_mean_loss: 0.0448 - x_sigma_loss: 0.0129 - y_mean_loss: 0.0210 - y_sigma_loss: 0.0016 - classification_loss: 0.0067\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.1395 - amplitude_loss: 0.0528 - x_mean_loss: 0.0441 - x_sigma_loss: 0.0120 - y_mean_loss: 0.0214 - y_sigma_loss: 0.0015 - classification_loss: 0.0078\n",
      "\t Saved model /Users/thsyu/Software/ml_projects/cnn_gaussian/2d_gaussian/model_003_save.hdf5\n",
      "loss >#1: 0.836\n",
      "amplitude_loss >#1: 0.256\n",
      "x_mean_loss >#1: 0.159\n",
      "x_sigma_loss >#1: 0.044\n",
      "y_mean_loss >#1: 0.053\n",
      "y_sigma_loss >#1: 0.003\n",
      "classification_loss >#1: 0.318\n",
      "\n",
      " \n",
      " 4\n",
      "\t Hyperparameters:\n",
      "{'learning_rate': 0.003, 'lr_decay': 0.0, 'num_epochs': 30, 'batch_size': 128, 'conv_filter_1': 16, 'conv_filter_2': 4, 'conv_kernel_1': 5, 'conv_kernel_2': 3, 'pool_kernel_1': 4, 'fc1_neurons': 64}\n",
      "\t Saved hyperparameters!\n",
      "\t Generated hyperparameters\n",
      "\t Generated dataset\n",
      "\t Creating model model_004\n",
      "\t Building model from hyperparameters...\n",
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 3.2397 - amplitude_loss: 2.1937 - x_mean_loss: 0.2442 - x_sigma_loss: 0.3992 - y_mean_loss: 0.1856 - y_sigma_loss: 0.0630 - classification_loss: 0.1498\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.7133 - amplitude_loss: 0.3085 - x_mean_loss: 0.1428 - x_sigma_loss: 0.0519 - y_mean_loss: 0.0977 - y_sigma_loss: 0.0127 - classification_loss: 0.1001\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 7s 673us/step - loss: 0.5736 - amplitude_loss: 0.2165 - x_mean_loss: 0.1399 - x_sigma_loss: 0.0413 - y_mean_loss: 0.0816 - y_sigma_loss: 0.0080 - classification_loss: 0.0861\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.5458 - amplitude_loss: 0.2017 - x_mean_loss: 0.1397 - x_sigma_loss: 0.0403 - y_mean_loss: 0.0754 - y_sigma_loss: 0.0065 - classification_loss: 0.0820\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.5185 - amplitude_loss: 0.1922 - x_mean_loss: 0.1336 - x_sigma_loss: 0.0372 - y_mean_loss: 0.0717 - y_sigma_loss: 0.0055 - classification_loss: 0.0784\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.5107 - amplitude_loss: 0.1909 - x_mean_loss: 0.1326 - x_sigma_loss: 0.0369 - y_mean_loss: 0.0682 - y_sigma_loss: 0.0049 - classification_loss: 0.0776\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.4916 - amplitude_loss: 0.1778 - x_mean_loss: 0.1305 - x_sigma_loss: 0.0353 - y_mean_loss: 0.0662 - y_sigma_loss: 0.0043 - classification_loss: 0.0773\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 7s 671us/step - loss: 0.4850 - amplitude_loss: 0.1749 - x_mean_loss: 0.1293 - x_sigma_loss: 0.0351 - y_mean_loss: 0.0655 - y_sigma_loss: 0.0044 - classification_loss: 0.0761\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.4869 - amplitude_loss: 0.1783 - x_mean_loss: 0.1281 - x_sigma_loss: 0.0361 - y_mean_loss: 0.0653 - y_sigma_loss: 0.0038 - classification_loss: 0.0751\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.4804 - amplitude_loss: 0.1770 - x_mean_loss: 0.1278 - x_sigma_loss: 0.0345 - y_mean_loss: 0.0622 - y_sigma_loss: 0.0037 - classification_loss: 0.0751\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.4640 - amplitude_loss: 0.1658 - x_mean_loss: 0.1255 - x_sigma_loss: 0.0342 - y_mean_loss: 0.0612 - y_sigma_loss: 0.0035 - classification_loss: 0.0740\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.4653 - amplitude_loss: 0.1673 - x_mean_loss: 0.1254 - x_sigma_loss: 0.0338 - y_mean_loss: 0.0611 - y_sigma_loss: 0.0033 - classification_loss: 0.0742\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.4624 - amplitude_loss: 0.1675 - x_mean_loss: 0.1256 - x_sigma_loss: 0.0335 - y_mean_loss: 0.0600 - y_sigma_loss: 0.0034 - classification_loss: 0.0729\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.4642 - amplitude_loss: 0.1711 - x_mean_loss: 0.1248 - x_sigma_loss: 0.0346 - y_mean_loss: 0.0586 - y_sigma_loss: 0.0036 - classification_loss: 0.0715\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.4707 - amplitude_loss: 0.1748 - x_mean_loss: 0.1242 - x_sigma_loss: 0.0355 - y_mean_loss: 0.0596 - y_sigma_loss: 0.0036 - classification_loss: 0.0741\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 7s 675us/step - loss: 0.4555 - amplitude_loss: 0.1649 - x_mean_loss: 0.1235 - x_sigma_loss: 0.0338 - y_mean_loss: 0.0590 - y_sigma_loss: 0.0033 - classification_loss: 0.0706\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.4538 - amplitude_loss: 0.1691 - x_mean_loss: 0.1199 - x_sigma_loss: 0.0329 - y_mean_loss: 0.0586 - y_sigma_loss: 0.0030 - classification_loss: 0.0702\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.4487 - amplitude_loss: 0.1637 - x_mean_loss: 0.1203 - x_sigma_loss: 0.0333 - y_mean_loss: 0.0578 - y_sigma_loss: 0.0030 - classification_loss: 0.0703\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 7s 682us/step - loss: 0.4586 - amplitude_loss: 0.1746 - x_mean_loss: 0.1223 - x_sigma_loss: 0.0341 - y_mean_loss: 0.0566 - y_sigma_loss: 0.0031 - classification_loss: 0.0678\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 7s 673us/step - loss: 0.4378 - amplitude_loss: 0.1599 - x_mean_loss: 0.1182 - x_sigma_loss: 0.0322 - y_mean_loss: 0.0557 - y_sigma_loss: 0.0028 - classification_loss: 0.0688\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.4495 - amplitude_loss: 0.1711 - x_mean_loss: 0.1185 - x_sigma_loss: 0.0336 - y_mean_loss: 0.0549 - y_sigma_loss: 0.0029 - classification_loss: 0.0688\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.4313 - amplitude_loss: 0.1570 - x_mean_loss: 0.1156 - x_sigma_loss: 0.0315 - y_mean_loss: 0.0555 - y_sigma_loss: 0.0027 - classification_loss: 0.0686\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.4259 - amplitude_loss: 0.1548 - x_mean_loss: 0.1169 - x_sigma_loss: 0.0316 - y_mean_loss: 0.0527 - y_sigma_loss: 0.0026 - classification_loss: 0.0671\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 7s 676us/step - loss: 0.4176 - amplitude_loss: 0.1500 - x_mean_loss: 0.1147 - x_sigma_loss: 0.0305 - y_mean_loss: 0.0551 - y_sigma_loss: 0.0026 - classification_loss: 0.0649\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.4217 - amplitude_loss: 0.1534 - x_mean_loss: 0.1152 - x_sigma_loss: 0.0308 - y_mean_loss: 0.0524 - y_sigma_loss: 0.0026 - classification_loss: 0.0671\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.4285 - amplitude_loss: 0.1592 - x_mean_loss: 0.1160 - x_sigma_loss: 0.0309 - y_mean_loss: 0.0541 - y_sigma_loss: 0.0025 - classification_loss: 0.0657\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 7s 671us/step - loss: 0.4193 - amplitude_loss: 0.1521 - x_mean_loss: 0.1151 - x_sigma_loss: 0.0309 - y_mean_loss: 0.0527 - y_sigma_loss: 0.0026 - classification_loss: 0.0658\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 7s 667us/step - loss: 0.4001 - amplitude_loss: 0.1439 - x_mean_loss: 0.1130 - x_sigma_loss: 0.0283 - y_mean_loss: 0.0520 - y_sigma_loss: 0.0025 - classification_loss: 0.0607\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.4079 - amplitude_loss: 0.1478 - x_mean_loss: 0.1139 - x_sigma_loss: 0.0293 - y_mean_loss: 0.0537 - y_sigma_loss: 0.0024 - classification_loss: 0.0606\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.4048 - amplitude_loss: 0.1486 - x_mean_loss: 0.1113 - x_sigma_loss: 0.0294 - y_mean_loss: 0.0523 - y_sigma_loss: 0.0025 - classification_loss: 0.0609\n",
      "\t Saved model /Users/thsyu/Software/ml_projects/cnn_gaussian/2d_gaussian/model_004_save.hdf5\n",
      "loss >#1: 0.482\n",
      "amplitude_loss >#1: 0.174\n",
      "x_mean_loss >#1: 0.137\n",
      "x_sigma_loss >#1: 0.033\n",
      "y_mean_loss >#1: 0.053\n",
      "y_sigma_loss >#1: 0.002\n",
      "classification_loss >#1: 0.084\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epochs\n",
    "if False:\n",
    "    # Generate data\n",
    "    generate_dataset()\n",
    "else:\n",
    "    # Once the data exist, run the experiment\n",
    "    m_init = 0\n",
    "    # mnum sets the number of model fitting + evaluations using *different* sets of hyperparameters\n",
    "    mnum = m_init\n",
    "    while True:\n",
    "        try:\n",
    "            print ('\\n \\n', mnum)\n",
    "            # repeats sets the number of model fitting + evaluations using the same set of hyperparameters\n",
    "            # but with different initial starting points/values for the trainable parameters (weights, biases, etc.)\n",
    "            localise_features(mnum, repeats=1, restart=False)\n",
    "            # use restart=True when want to rerun a specific model\n",
    "            #localise_features(mnum, repeats=3, restart=True)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        mnum += 1\n",
    "        if mnum >= m_init+5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_002_save.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate low-amp vs high-amp Gaussians and plot the above 5 plots to see if there is \n",
    "# a larger scatter for true vs predicted in low-amp Gaussians\n",
    "a, b, _, _, c, _ = generate_dataset()\n",
    "\n",
    "low_Z = np.where(b[:,0]/10. < 0.5)[0]\n",
    "\n",
    "print (len(low_Z), len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pamp, pxmu, pxsig, pymu, pysig, cls = model.predict(a, batch_size=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the relation between true and predicted means, sigmas\n",
    "oto_amp = np.linspace(1., 10., 32) #one-to-one relation for amplitudes\n",
    "oto_means = np.linspace(-1., 1., 32) # one-to-one relation for means\n",
    "oto_sigmas = np.linspace(0.25, 4.0, 32) # one-to-one relation for sigmas\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 4))\n",
    "\n",
    "# Plot the true y's and predicted y's from the NN model\n",
    "ax1.scatter(b[:, 0], pamp.flatten(), marker='.')\n",
    "ax1.scatter(b[:, 0][low_Z], pamp.flatten()[low_Z], marker='.')\n",
    "# Plot the 1-to-1 line\n",
    "ax1.plot(oto_amp, oto_amp, color='black', ls='--')\n",
    "ax1.set_xlabel('True value')\n",
    "ax1.set_ylabel('Predicted value')\n",
    "ax1.set_title(r'Gaussian Amplitude')\n",
    "\n",
    "ax2.scatter(b[:, 1], pxmu.flatten(), marker='.')\n",
    "ax2.plot(oto_means, oto_means, color='black', ls='--')\n",
    "ax2.set_xlabel('True value')\n",
    "ax2.set_ylabel('Predicted value')\n",
    "ax2.set_title(r'Gaussian x-$\\mu$')\n",
    "\n",
    "ax3.scatter(b[:, 2], pxsig.flatten(), marker='.')\n",
    "ax3.plot(oto_sigmas, oto_sigmas, color='black', ls='--')\n",
    "ax3.set_xlabel('True value')\n",
    "ax3.set_ylabel('Predicted value')\n",
    "ax3.set_title(r'Gaussian x-$\\sigma$')\n",
    "\n",
    "ax4.scatter(b[:, 3], pymu.flatten(), marker='.')\n",
    "ax4.plot(oto_means, oto_means, color='black', ls='--')\n",
    "ax4.set_xlabel('True value')\n",
    "ax4.set_ylabel('Predicted value')\n",
    "ax4.set_title(r'Gaussian y-$\\mu$')\n",
    "\n",
    "ax5.scatter(b[:, 4], pysig.flatten(), marker='.')\n",
    "ax5.plot(oto_sigmas, oto_sigmas, color='black', ls='--')\n",
    "ax5.set_xlabel('True value')\n",
    "ax5.set_ylabel('Predicted value')\n",
    "ax5.set_title(r'Gaussian y-$\\sigma$')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "ax1.hist(b[:, 0] - pamp.flatten(), density=True, bins=30, alpha=0.5, label='All')\n",
    "ax1.hist(b[:, 0][low_Z] - pamp.flatten()[low_Z], density=True, bins=30, alpha=0.5, label='Low Z')\n",
    "ax1.axvline(0.0, ls='--', color='black', alpha=0.5)\n",
    "ax1.legend()\n",
    "ax1.set_title(r'Gaussian amplitude')\n",
    "ax1.set_xlabel('(true - predicted) value')\n",
    "\n",
    "ax2.hist(b[:, 1] - pxmu.flatten(), density=True, bins=30, alpha=0.5)\n",
    "ax2.hist(b[:, 1][low_Z] - pxmu.flatten()[low_Z], density=True, bins=30, alpha=0.5)\n",
    "ax2.axvline(0.0, ls='--', color='black', alpha=0.5)\n",
    "ax2.set_title(r'Gaussian x-$\\mu$')\n",
    "ax2.set_xlabel('(true - predicted) value')\n",
    "\n",
    "ax3.hist(b[:, 2] - pxsig.flatten(), density=True, bins=30, alpha=0.5)\n",
    "ax3.hist(b[:, 2][low_Z] - pxsig.flatten()[low_Z], density=True, bins=30, alpha=0.5)\n",
    "ax3.axvline(0.0, ls='--', color='black', alpha=0.5)\n",
    "ax3.set_title(r'Gaussian x-$\\sigma$')\n",
    "ax3.set_xlabel('(true - predicted) value')\n",
    "\n",
    "ax4.hist(b[:, 3] - pymu.flatten(), density=True, bins=30, alpha=0.5)\n",
    "ax4.hist(b[:, 3][low_Z] - pymu.flatten()[low_Z], density=True, bins=30, alpha=0.5)\n",
    "ax4.axvline(0.0, ls='--', color='black', alpha=0.5)\n",
    "ax4.set_title(r'Gaussian y-$\\mu$')\n",
    "ax4.set_xlabel('(true - predicted) value')\n",
    "\n",
    "ax5.hist(b[:, 4] - pysig.flatten(), density=True, bins=30, alpha=0.5)\n",
    "ax5.hist(b[:, 4][low_Z] - pysig.flatten()[low_Z], density=True, bins=30, alpha=0.5)\n",
    "ax5.axvline(0.0, ls='--', color='black', alpha=0.5)\n",
    "ax5.set_title(r'Gaussian y-$\\sigma$')\n",
    "ax5.set_xlabel('(true - predicted) value')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - (100*676/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(c - cls.flatten().astype(int) == 1.)[0]), len(np.where(c - cls.flatten().astype(int) == 0.)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 2D Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for 3d plotting\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x, y grid, and use it to generate a 2d Gaussian\n",
    "x_vals = np.linspace(-10, 10, 32)\n",
    "y_vals = np.linspace(-10, 10, 32)\n",
    "\n",
    "x, y = np.meshgrid(x_vals, y_vals)\n",
    "\n",
    "z = gaussian2d(x, y, 1, 0, 2, 0, 2)\n",
    "\n",
    "# Plot 2d Gaussian\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(x, y, z, rstride=1, cstride=2, cmap='winter')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
